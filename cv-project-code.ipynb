{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install patchify","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYYGsBzvzLJf","outputId":"349465d3-6f4b-45e1-8686-ed8f1d34337e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U segmentation-models","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5S2KSfezUg6","outputId":"0cabdda3-0531-498f-93b6-8e56742ccbb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\n\nimport os\nimport sys\nfrom tempfile import NamedTemporaryFile\nfrom urllib.request import urlopen\nfrom urllib.parse import unquote, urlparse\nfrom urllib.error import HTTPError\nfrom zipfile import ZipFile\nimport tarfile\nimport shutil\n\nCHUNK_SIZE = 40960\nDATA_SOURCE_MAPPING = 'cvproject:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4610753%2F7860162%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240408%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240408T141934Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6a491ae7dada1238235e5a33e81a57cc1e141e597ff67f2de3022cb86b24454f78bbf6e628301dd12ae80354746e8f3ff54cabdff76828e0c936725f0899768c595a7b7f4430a724e3d0c34fcf940dafa6c8ca5595096f916e8fbc5d42da80963bf8a99b8a29abd52037ba256073c4ab75222e733fea6ac2114156bf33b5a78892bbd3426f2dc82d9df150331ad6721902f5bbe76b7b8a60ef7aef5f36a18298e96f67950423deeae5307fe7b09577c114fe1c4a92e3536642ad377ae83ff31407b38e6331a8bca97635e415238c0331ccbc35b57ee8e0063126e918bb912519f4f03763e9bcc7296cc9b597a6b42ab4474504042a9ba64f3ad3c42615d44f3a'\n\nKAGGLE_INPUT_PATH='/kaggle/input'\nKAGGLE_WORKING_PATH='/kaggle/working'\nKAGGLE_SYMLINK='kaggle'\n\n!umount /kaggle/input/ 2> /dev/null\nshutil.rmtree('/kaggle/input', ignore_errors=True)\nos.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\nos.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n\ntry:\n  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\nexcept FileExistsError:\n  pass\ntry:\n  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\nexcept FileExistsError:\n  pass\n\nfor data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n    directory, download_url_encoded = data_source_mapping.split(':')\n    download_url = unquote(download_url_encoded)\n    filename = urlparse(download_url).path\n    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n    try:\n        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n            total_length = fileres.headers['content-length']\n            print(f'Downloading {directory}, {total_length} bytes compressed')\n            dl = 0\n            data = fileres.read(CHUNK_SIZE)\n            while len(data) > 0:\n                dl += len(data)\n                tfile.write(data)\n                done = int(50 * dl / int(total_length))\n                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n                sys.stdout.flush()\n                data = fileres.read(CHUNK_SIZE)\n            if filename.endswith('.zip'):\n              with ZipFile(tfile) as zfile:\n                zfile.extractall(destination_path)\n            else:\n              with tarfile.open(tfile.name) as tarfile:\n                tarfile.extractall(destination_path)\n            print(f'\\nDownloaded and uncompressed: {directory}')\n    except HTTPError as e:\n        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n        continue\n    except OSError as e:\n        print(f'Failed to load {download_url} to path {destination_path}')\n        continue\n\nprint('Data source import complete.')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KhzFY6CRzt2S","outputId":"971cf19b-75ee-4276-d0f5-3a1f2f07c531"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport glob\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n# from patchify import patchify\nimport tifffile as tiff\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\nimport segmentation_models as sm\nfrom tensorflow.keras.metrics import MeanIoU\nimport random","metadata":{"id":"9qLXbouWy3ie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Quick understanding of the dataset\ntemp_img = cv2.imread(\"/kaggle/input/cvproject/augmented_dataset/images/train/12_13.jpg\") #3 channels / spectral bands\nplt.imshow(temp_img[:,:,2]) #View each channel...\ntemp_mask = cv2.imread(\"/kaggle/input/cvproject/augmented_dataset/masks/train/12_13.png\") #3 channels but all same.\nlabels, count = np.unique(temp_mask[:,:,0], return_counts=True) #Check for each channel. All chanels are identical\nprint(\"Labels are: \", labels, \" and the counts are: \", count)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"zkIrxU-4zPhI","outputId":"c3acf824-b9f7-4ee5-eff4-ad94ffe1afa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_path = \"/kaggle/input/cvproject/augmented_dataset/images/train\"\nmasks_path = \"/kaggle/input/cvproject/augmented_dataset/masks/train\"","metadata":{"id":"B8V2GXJZz0hF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n# Total Images\nIMAGE_PATH = Path(images_path)\nIMAGE_PATH_LIST = list(IMAGE_PATH.glob(\"*.jpg\"))\nIMAGE_PATH_LIST = sorted(IMAGE_PATH_LIST)\n\nprint(f'Total Images = {len(IMAGE_PATH_LIST)}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y7PRv3uLz6fY","outputId":"a799c578-7ed6-40a1-90b5-91c58e71f40d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total Masks\nMASK_PATH = Path(masks_path)\nMASK_PATH_LIST = list(MASK_PATH.glob(\"*.png\"))\nMASK_PATH_LIST = sorted(MASK_PATH_LIST)\n\nprint(f'Total Masks = {len(MASK_PATH_LIST)}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtpMBo31z8Ig","outputId":"8803cae4-9de5-45c2-e2b1-1e020422e223"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimages_paths = [None] * len(IMAGE_PATH_LIST)\nmasks_paths = [None] * len(MASK_PATH_LIST)\n\nfor i,(img_path, mask_path) in enumerate(zip(IMAGE_PATH_LIST, MASK_PATH_LIST)):\n    images_paths[i] = img_path\n    masks_paths[i] = mask_path\n\ndata = pd.DataFrame({'Image':images_paths, 'Mask':masks_paths})\ndata","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"9z3_7bRnz-Fa","outputId":"cc99179f-113c-4d5d-964d-7367e62507e6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBqrz5FX0AKN","outputId":"83109caa-cad7-46f5-ce33-1cc37e3716a8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_directory = '/content/drive/MyDrive/'","metadata":{"id":"gEbny0SM0Dy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(root_directory + \"256_patches/images/\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/masks/\", exist_ok=True)","metadata":{"id":"lfmgBAho0FgA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patch_size = 256","metadata":{"id":"uLsrMiJo0J0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_path in data['Image'].head(1000):\n    image_path = str(image_path)\n    image = cv2.imread(image_path, 1)\n    SIZE_X = (image.shape[1] // patch_size) * patch_size\n    SIZE_Y = (image.shape[0] // patch_size) * patch_size\n    image = Image.fromarray(image)\n    image = image.crop((0, 0, SIZE_X, SIZE_Y))\n    image = np.array(image)\n\n    print(\"Now patchifying image:\", image_path)\n    patches_img = patchify(image, (256, 256, 3), step=256)\n\n    for i in range(patches_img.shape[0]):\n        for j in range(patches_img.shape[1]):\n\n            single_patch_img = patches_img[i,j,:,:]\n            single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.\n\n            # Save the image patch to the drive\n            cv2.imwrite(root_directory+\"256_patches/images/\"+os.path.basename(image_path.split('.')[0])+\"_patch_\"+str(i)+str(j)+\".jpg\", single_patch_img)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"berdaGas0LoC","outputId":"8bdc5e18-9524-4804-9004-f451cbd4efd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for mask_path in data['Mask'].head(1000):\n    mask_path = str(mask_path)  # Ensure the path is converted to a string\n    mask = cv2.imread(mask_path, 1)  # Read each image as Grey (or color but remember to map each color to an integer)\n    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n    SIZE_X = (mask.shape[1] // patch_size) * patch_size  # Nearest size divisible by our patch size\n    SIZE_Y = (mask.shape[0] // patch_size) * patch_size  # Nearest size divisible by our patch size\n    mask = Image.fromarray(mask)\n    mask = mask.crop((0, 0, SIZE_X, SIZE_Y))  # Crop from top left corner\n    mask = np.array(mask)\n\n    print(\"Now patchifying mask:\", mask_path)\n    patches_img = patchify(mask, (256, 256, 3), step=256)\n\n    for i in range(patches_img.shape[0]):\n        for j in range(patches_img.shape[1]):\n\n            single_patch_img = patches_img[i,j,:,:]\n            #single_patch_img = (single_patch_img.astype('float32')) / 255. #We will preprocess using one of the backbones\n            single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.\n\n            # Save the image patch to the drive\n            cv2.imwrite(root_directory+\"256_patches/masks/\"+os.path.basename(mask_path.split('.')[0])+\"_patch_\"+str(i)+str(j)+\".png\", single_patch_img)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Mjac6Ki0Oen","outputId":"40391ce1-f36b-4fe0-b9ea-e30d62d90baf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_dir = \"/content/drive/MyDrive/256_patches/images/\"\ntrain_mask_dir = \"/content/drive/MyDrive/256_patches/masks/\"","metadata":{"id":"GA98RP250YnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = os.listdir(train_img_dir)\nmsk_list = os.listdir(train_mask_dir)","metadata":{"id":"L4Z6xIN-0hEi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_images = len(os.listdir(train_img_dir))\nnum_images","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ot0NO5ER0kf9","outputId":"ece7ee2c-41af-4036-863f-3c584d63d294"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = random.randint(0, num_images-1)","metadata":{"id":"_BRgYoNB0l-f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\nimg_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)","metadata":{"id":"U47Q0GRA0nih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(121)\nplt.imshow(img_for_plot)\nplt.title('Image')\nplt.subplot(122)\nplt.imshow(mask_for_plot, cmap='gray')\nplt.title('Mask')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"67eJtX5z0pbl","outputId":"8854400f-9625-4d25-fba1-1d39402bfb8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(root_directory + \"256_patches/images_with_useful_info/images/\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/images_with_useful_info/masks/\", exist_ok=True)","metadata":{"id":"Brxf7nUr0rLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useless=0  #Useless image counter\nfor img in range(len(img_list)):   #Using t1_list as all lists are of same size\n    img_name=img_list[img]\n    mask_name = msk_list[img]\n    print(\"Now preparing image and masks number: \", img)\n\n    temp_image=cv2.imread(train_img_dir+img_list[img], 1)\n\n    temp_mask=cv2.imread(train_mask_dir+msk_list[img], 0)\n    #temp_mask=temp_mask.astype(np.uint8)\n\n    val, counts = np.unique(temp_mask, return_counts=True)\n\n    if (1 - (counts[0]/counts.sum())) > 0.05:  #At least 5% useful area with labels that are not 0\n        print(\"Save Me\")\n        cv2.imwrite('/content/drive/MyDrive/256_patches/images_with_useful_info/images/'+img_name, temp_image)\n        cv2.imwrite('/content/drive/MyDrive/256_patches/images_with_useful_info/masks/'+mask_name, temp_mask)\n\n    else:\n        print(\"I am useless\")\n        useless +=1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjNMMwmf1_Be","outputId":"8cb4c8de-382e-4389-b0e9-f62e82929a0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total useful images are: \", len(img_list)-useless)\nprint(\"Total useless images are: \", useless)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4J1x3uzA2KNB","outputId":"ccdac3ac-663c-452f-f70b-b4046378ff6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(root_directory + \"256_patches/finaldata/\", exist_ok=True)","metadata":{"id":"LW61gBsV3dU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install split-folders","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_usyhuK3qDI","outputId":"bfc7c86f-bb4f-4d92-f527-f25830f5f500"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import splitfolders  # or import split_folders\n\ninput_folder = '/content/drive/MyDrive/256_patches/images_with_useful_info/'\noutput_folder = '/content/drive/MyDrive/256_patches/finaldata/'\n# Split with a ratio.\n# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\nsplitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25), group_prefix=None)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iHGxOsFk26QF","outputId":"6e0c33e0-2f68-42a3-a977-441daf01177e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_dir = \"/content/drive/MyDrive/256_patches/data_train_final/train_images/\"\ntrain_mask_dir = \"/content/drive/MyDrive/256_patches/data_train_final/train_masks/\"","metadata":{"id":"T1HLY_Z136el"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = os.listdir(train_img_dir)\nmsk_list = os.listdir(train_mask_dir)","metadata":{"id":"U0oHGyj765Ug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_images = len(os.listdir(train_img_dir))\n","metadata":{"id":"hme3Ygcs68Tv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = random.randint(0, num_images-1)\n\nimg_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\nimg_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n\nmask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(121)\nplt.imshow(img_for_plot)\nplt.title('Image')\nplt.subplot(122)\nplt.imshow(mask_for_plot, cmap='gray')\nplt.title('Mask')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"Z8gbOCl-69-O","outputId":"db954990-bd37-468d-ecbd-75f075fc669c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(root_directory + \"256_patches/data_train_fi/\", exist_ok=True)","metadata":{"id":"aL1qq1auCpgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(root_directory + \"256_patches/data_train_fi/train_images\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/data_train_fi/train_masks\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/data_train_fi/val_images\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/data_train_fi/val_masks\", exist_ok=True)","metadata":{"id":"XeezMDp7DBjh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(root_directory + \"256_patches/data_train_fi/train_images/train/\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/data_train_fi/train_masks/train/\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/data_train_fi/val_images/val/\", exist_ok=True)\nos.makedirs(root_directory + \"256_patches/data_train_fi/val_masks/val\", exist_ok=True)","metadata":{"id":"9EGBdN3MLAyk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\ndef copy_files(source_folder, destination_folder):\n    # Check if source folder exists\n    if not os.path.exists(source_folder):\n        print(f\"Source folder '{source_folder}' does not exist.\")\n        return\n\n    # Check if destination folder exists, create it if it doesn't\n    if not os.path.exists(destination_folder):\n        os.makedirs(destination_folder)\n\n    # Get list of files in the source folder\n    files = os.listdir(source_folder)\n\n    # Iterate over each file and copy it to the destination folder\n    for file in files:\n        source_file = os.path.join(source_folder, file)\n        destination_file = os.path.join(destination_folder, file)\n        shutil.copy2(source_file, destination_file)\n        print(f\"File '{file}' copied to '{destination_folder}'.\")","metadata":{"id":"v0gkgwXYDcM7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_folder = \"/content/drive/MyDrive/256_patches/finaldata/val/masks\"\ndestination_folder = \"/content/drive/MyDrive/256_patches/data_train_fi/val_masks/val\"\ncopy_files(source_folder, destination_folder)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjM74Qv_Dgqq","outputId":"70f14446-7c88-4893-d14d-ea4b953d0b59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_directory_img = '/content/drive/MyDrive/256_patches/data_train_fi/train_images/train'\nroot_directory_msk = '/content/drive/MyDrive/256_patches/data_train_fi/train_masks/train'","metadata":{"id":"W-qxDqMyQ9_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_directory_img","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"UJz9JjINQ6Y-","outputId":"218fc927-2f89-40ac-ecdf-e7fe82fea090"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"xBquTDdwRILj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"fGhWII2NRK9Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-htPfyF3ROxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Nnk3fCwKRlYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Yftuz2vbRzFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"lXz7nlCQR15T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10ShKx3xR5Dp","outputId":"fc21ca61-2124-4d38-c22b-2fb026f3a076"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=24\nbatch_size= 16\nn_classes=6","metadata":{"id":"Zb0BhdAR7AhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfrom keras.utils import to_categorical\n","metadata":{"id":"t4V1JtBq7Glh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE = 'resnet50'\npreprocess_input = sm.get_preprocessing(BACKBONE)","metadata":{"id":"Yvz16TV27KpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"2UcqJzq8QA2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"4DsjiEneQEXe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UgAv0bfMQIho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"hcvXez-HSedY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndivider = '#6E4B26'.lstrip('#')\ndivider = np.array(tuple(int(divider[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n\nlane = '#87CEEB'.lstrip('#')\nlane = np.array(tuple(int(lane[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n\nroad = '#808000'.lstrip('#')\nroad = np.array(tuple(int(road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n\nzebra =  '#FFFFFF'.lstrip('#')\nzebra = np.array(tuple(int(zebra[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n\ndlane = '#F1700A'.lstrip('#')\ndlane = np.array(tuple(int(dlane[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n\nbackground = '#000000'.lstrip('#')\nbackground = np.array(tuple(int(background[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155\n\ndef rgb_to_2D_label(label):\n    \"\"\"\n    Supply our label masks as input in RGB format.\n    Replace pixels with specific RGB values...\n    \"\"\"\n    label_seg = np.zeros(label.shape, dtype=np.uint8)\n    label_seg[np.all(label == divider, axis=-1)] = 0\n    label_seg[np.all(label == road, axis=-1)] = 1\n    label_seg[np.all(label == lane, axis=-1)] = 2\n    label_seg[np.all(label == zebra, axis=-1)] = 3\n    label_seg[np.all(label == dlane, axis=-1)] = 4\n    label_seg[np.all(label == background, axis=-1)] = 5\n    return label_seg\n\ndef preprocess_data(img, mask, num_class):\n      # Scale images\n      scaler = MinMaxScaler()\n      img = scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)\n      img = preprocess_input(img)  #Preprocess based on the pretrained backbone...\n      # Convert mask to one-hot\n      mask = rgb_to_2D_label(mask)  # Convert RGB mask to 2D label\n      mask = to_categorical(mask, num_class)\n      return (img, mask)\n\n\n\n","metadata":{"id":"S8RrtvN67Mo3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndef trainGenerator(train_img_path, train_mask_path, num_class):\n    img_data_gen_args = dict(horizontal_flip=True,\n                      vertical_flip=True,\n                      fill_mode='reflect')\n\n    image_datagen = ImageDataGenerator()\n    mask_datagen = ImageDataGenerator()\n\n    image_generator = image_datagen.flow_from_directory(\n        train_img_path,\n        class_mode=None,  # Set to None to return only the images without labels\n        batch_size=batch_size,\n        seed=seed)\n\n    mask_generator = mask_datagen.flow_from_directory(\n        train_mask_path,\n        class_mode=None,  # Set to None to return only the masks without labels\n        color_mode='rgb',\n        batch_size=batch_size,\n        seed=seed)\n\n    for (img, mask) in zip(image_generator, mask_generator):\n        img, mask = preprocess_data(img, mask, num_class)\n        yield img, mask\n","metadata":{"id":"GmznwvVy7PE0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_path = \"/content/drive/MyDrive/256_patches/data_train_fi/train_images/\"\ntrain_mask_path = \"/content/drive/MyDrive/256_patches/data_train_fi/train_masks/\"","metadata":{"id":"TEI9wKck7Zd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"toHBdOipGft3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_gen = trainGenerator(train_img_path, train_mask_path, num_class=6)","metadata":{"id":"kSZeJBo37SG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_img_path = \"/content/drive/MyDrive/256_patches/data_train_fi/val_images/\"\nval_mask_path = \"/content/drive/MyDrive/256_patches/data_train_fi/val_masks/\"\nval_img_gen = trainGenerator(val_img_path, val_mask_path, num_class=6)\n","metadata":{"id":"Nf7AIWa77fgC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = train_img_gen.__next__()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-vXIaxq7mT2","outputId":"b2ef2a5d-546c-46b7-cd27-5ee551a6237c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val, y_val = val_img_gen.__next__()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upRLvbZwJx54","outputId":"e82d88e8-5659-4e6a-c439-9ba665d656bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,3):\n    image = x[i]\n    mask = np.argmax(y[i], axis=2)\n    plt.subplot(1,2,1)\n    plt.imshow(image)\n    plt.subplot(1,2,2)\n    plt.imshow(mask, cmap='gray')\n    plt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621},"id":"X7wTHnZ57oaP","outputId":"268b0988-f560-4d48-87a9-fae577c80276"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train_imgs = len(os.listdir('/content/drive/MyDrive/256_patches/data_train_fi/train_images/train/'))\nnum_val_images = len(os.listdir('/content/drive/MyDrive/256_patches/data_train_fi/val_images/val/'))\nsteps_per_epoch = num_train_imgs//batch_size\nval_steps_per_epoch = num_val_images//batch_size","metadata":{"id":"ZoXmZX2D9GfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_HEIGHT = x.shape[1]\nIMG_WIDTH  = x.shape[2]\nIMG_CHANNELS = x.shape[3]","metadata":{"id":"mSQH9HOmPJM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"PmyilUjFVync"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"4sv0haJsV6tI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"fhVQEz-PV7-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_img_gen,\n          steps_per_epoch=steps_per_epoch,\n          epochs=25,\n          verbose=1,\n          validation_data=val_img_gen,\n          validation_steps=val_steps_per_epoch)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_pwFlhoFWFnv","outputId":"c96b3daf-d643-48c8-b2ac-3fabe17705bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = sm.Unet(BACKBONE, encoder_weights='imagenet',\n                input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n                classes=n_classes, activation='softmax')\nmodel1.compile('Adam', loss='categorical_crossentropy', metrics=[sm.metrics.iou_score])","metadata":{"id":"IdDgB6kFPLqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"t9QC2LqxVQ4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model1.summary())\nprint(model1.input_shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Me6ZLMKPPJ6","outputId":"47b79738-b42d-4173-9c87-c872158dde3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model1.fit(train_img_gen,\n          steps_per_epoch=steps_per_epoch,\n          epochs=5,\n          verbose=1,\n          validation_data=val_img_gen,\n          validation_steps=val_steps_per_epoch)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48AXw4i5PT9T","outputId":"2d249f08-f0be-4827-a311-149c5f5923f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"E9VudcpxPZ-o","outputId":"5fe142e6-8be8-4a76-92a6-8d9b62d333fe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['iou_score']\nval_acc = history.history['val_iou_score']\n\nplt.plot(epochs, acc, 'y', label='Training IoU')\nplt.plot(epochs, val_acc, 'r', label='Validation IoU')\nplt.title('Training and validation IoU')\nplt.xlabel('Epochs')\nplt.ylabel('IoU')\nplt.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"6KaFNYTjTH57","outputId":"0ec92c11-8712-4623-c94e-d04c43acdb3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_batch, test_mask_batch = val_img_gen.__next__()","metadata":{"id":"EEWotgxiTH4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3)\ntest_pred_batch = model.predict(test_image_batch)\ntest_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pHzAlrsTH1v","outputId":"7f907279-3b67-4d81-d5f2-f5c7d5530f06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = random.randint(0, test_image_batch.shape[0]-1)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(231)\nplt.title('Testing Image')\nplt.imshow(test_image_batch[img_num])\nplt.subplot(232)\nplt.title('Testing Label')\nplt.imshow(test_mask_batch_argmax[img_num])\nplt.subplot(233)\nplt.title('Prediction on test image')\nplt.imshow(test_pred_batch_argmax[img_num])\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"nS79pq5kTHzZ","outputId":"4c36df76-831e-45a1-8023-9964db94f736"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\n\nimport os\nimport sys\nfrom tempfile import NamedTemporaryFile\nfrom urllib.request import urlopen\nfrom urllib.parse import unquote, urlparse\nfrom urllib.error import HTTPError\nfrom zipfile import ZipFile\nimport tarfile\nimport shutil\n\nCHUNK_SIZE = 40960\nDATA_SOURCE_MAPPING = 'cvproject:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4610753%2F7860162%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240408%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240408T195953Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3ec4ba340ec4665069b52e82f71b28f3d2eec944c1115d45416f58d504eb0898a23461944a6e3a057150492d7943804eba1d5d7afdd3172a98a22221d1cf71f0c401e3be7bb43beed4198d3c71c7029e812e70d44205f5acfc473fe063dfff7da9fcea48be64f12f68fcea0c09d102f79043674b603633a3dac8c38cbe9b7d192bf8afdabfd457093de1d8c3f40dc9398c07a8db0dff2181702db1bd8728bacdb97baab7951c6d3ade19629fec582916708e44c5e8b5d615d1f2c00b81cc58573b4e943ada27b2ea8ba152e538a01a6d17cae6e20573ecc48a464d14de22ae5fa5ee1e8e69c96e4993f500629432c4758e287a58ddceb70c0dc0c57675483a95'\n\nKAGGLE_INPUT_PATH='/kaggle/input'\nKAGGLE_WORKING_PATH='/kaggle/working'\nKAGGLE_SYMLINK='kaggle'\n\n!umount /kaggle/input/ 2> /dev/null\nshutil.rmtree('/kaggle/input', ignore_errors=True)\nos.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\nos.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n\ntry:\n  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\nexcept FileExistsError:\n  pass\ntry:\n  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\nexcept FileExistsError:\n  pass\n\nfor data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n    directory, download_url_encoded = data_source_mapping.split(':')\n    download_url = unquote(download_url_encoded)\n    filename = urlparse(download_url).path\n    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n    try:\n        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n            total_length = fileres.headers['content-length']\n            print(f'Downloading {directory}, {total_length} bytes compressed')\n            dl = 0\n            data = fileres.read(CHUNK_SIZE)\n            while len(data) > 0:\n                dl += len(data)\n                tfile.write(data)\n                done = int(50 * dl / int(total_length))\n                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n                sys.stdout.flush()\n                data = fileres.read(CHUNK_SIZE)\n            if filename.endswith('.zip'):\n              with ZipFile(tfile) as zfile:\n                zfile.extractall(destination_path)\n            else:\n              with tarfile.open(tfile.name) as tarfile:\n                tarfile.extractall(destination_path)\n            print(f'\\nDownloaded and uncompressed: {directory}')\n    except HTTPError as e:\n        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n        continue\n    except OSError as e:\n        print(f'Failed to load {download_url} to path {destination_path}')\n        continue\n\nprint('Data source import complete.')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hwc9GPrATHxI","outputId":"2faebf2e-92f7-446c-e45d-1dfa985d13f4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"is-bGerNTIXO"},"execution_count":null,"outputs":[]}]}